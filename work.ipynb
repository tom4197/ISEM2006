{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "7KH5zer3JDpY",
      "metadata": {
        "id": "7KH5zer3JDpY"
      },
      "source": [
        "#STEP 1 : Data acquisition and curation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "ApJZlfWPucxD",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ApJZlfWPucxD",
        "outputId": "a75d519b-ad6a-4b8d-ec29-5836e604eda3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: PyPDF2 in c:\\users\\bobch\\anaconda3\\envs\\default\\lib\\site-packages (3.0.1)\n",
            "Requirement already satisfied: typing_extensions>=3.10.0.0 in c:\\users\\bobch\\anaconda3\\envs\\default\\lib\\site-packages (from PyPDF2) (4.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install PyPDF2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "7b95fac8",
      "metadata": {
        "id": "7b95fac8"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import re\n",
        "import os\n",
        "import PyPDF2\n",
        "import csv\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from collections import Counter\n",
        "from nltk.util import ngrams\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "537e6c07",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "537e6c07",
        "outputId": "f59a2c64-18aa-48d0-e4e1-1a5106a2dfa5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     C:\\Users\\bobch\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\bobch\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to\n",
            "[nltk_data]     C:\\Users\\bobch\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\bobch\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "cJv-Il6CEwB6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cJv-Il6CEwB6",
        "outputId": "f7e42e90-9e36-42db-f9a9-503437effd09"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "C:\\Users\\bobch\\OneDrive\\桌面\\ISEM2006 WhatsApp\\ISEM2006 Group Project\\src\n",
            "C:\\Users\\bobch\\OneDrive\\桌面\\ISEM2006 WhatsApp\\ISEM2006 Group Project\\src\\CVBF Letter to Shareholders 2015-2017.pdf\n",
            "C:\\Users\\bobch\\OneDrive\\桌面\\ISEM2006 WhatsApp\\ISEM2006 Group Project\\src\\HIBB Letter to Shareholders 2015-2017.pdf\n",
            "C:\\Users\\bobch\\OneDrive\\桌面\\ISEM2006 WhatsApp\\ISEM2006 Group Project\\src\\HMSY Letter to Shareholders 2015-2017.pdf\n",
            "C:\\Users\\bobch\\OneDrive\\桌面\\ISEM2006 WhatsApp\\ISEM2006 Group Project\\src\\KELYA Letter to Shareholders 2015-2017.pdf\n",
            "C:\\Users\\bobch\\OneDrive\\桌面\\ISEM2006 WhatsApp\\ISEM2006 Group Project\\src\\Python - Amazone letter to shareholdesr.pdf\n",
            "C:\\Users\\bobch\\OneDrive\\桌面\\ISEM2006 WhatsApp\\ISEM2006 Group Project\\src\\Python - Letters to shareholders Abbott.pdf\n",
            "C:\\Users\\bobch\\OneDrive\\桌面\\ISEM2006 WhatsApp\\ISEM2006 Group Project\\src\\Python - Letters to Shareholders JPMorgan Chase & Co..pdf\n",
            "C:\\Users\\bobch\\OneDrive\\桌面\\ISEM2006 WhatsApp\\ISEM2006 Group Project\\src\\Python - Walmart Letters to shareholders.pdf\n",
            "Number of letter extracted : 8\n"
          ]
        }
      ],
      "source": [
        "#!!! PUT YOUR OWN FOLDER PATH BELOW !!!\n",
        "#Path of the folder\n",
        "PDF_FOLDER_PATH = r\"C:\\Users\\bobch\\OneDrive\\桌面\\ISEM2006 WhatsApp\\ISEM2006 Group Project\\src\"\n",
        "\n",
        "#Example PDF_FOLDER_PATH = \"/path/folder/projet/src\"\n",
        "\n",
        "\n",
        "def read_pdf(file_path):\n",
        "    reader = PyPDF2.PdfReader(file_path)\n",
        "    texts = []\n",
        "    for page in reader.pages:\n",
        "      text = page.extract_text()\n",
        "      text = text.strip('')\n",
        "      text = text.replace('\\n', ' ')\n",
        "      text = re.sub(r'\\s+', ' ', text)\n",
        "      texts.append(text)\n",
        "    texts = ''.join(texts)\n",
        "    return texts\n",
        "\n",
        "\n",
        "# import all pdfs in folder\n",
        "upper_dir = os.getcwd()\n",
        "current_dir = PDF_FOLDER_PATH\n",
        "print(current_dir)\n",
        "pdf_list = []\n",
        "for file in os.listdir(current_dir):\n",
        "    if file.endswith('.pdf'):\n",
        "        pdf_list.append(os.path.join(current_dir, file)) # Changed to use os.path.join\n",
        "print('\\n'.join(pdf_list))\n",
        "letter_list = []\n",
        "for pdf in pdf_list:\n",
        "    text = read_pdf(pdf)\n",
        "    letter_list.append(text)\n",
        "\n",
        "print(f\"Number of letter extracted : {len(letter_list)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "7a1fc709",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7a1fc709",
        "outputId": "68f88cc4-1dec-45dc-c742-ec07faa148cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data successfully exported to C:\\Users\\bobch\\OneDrive\\桌面\\ISEM2006 WhatsApp\\ISEM2006 Group Project\\src\\output.csv\n"
          ]
        }
      ],
      "source": [
        "filename = current_dir + '\\\\' + 'output.csv'\n",
        "# Open the file in write mode ('w') with newline='' to handle line endings correctly\n",
        "with open(filename, 'w', newline='') as csvfile:\n",
        "    # Create a CSV writer object\n",
        "    csv_writer = csv.writer(csvfile)\n",
        "\n",
        "    # Write the data\n",
        "    for letter in letter_list:\n",
        "        csv_writer.writerow([letter])\n",
        "\n",
        "print(f\"Data successfully exported to {filename}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "72b79d1d",
      "metadata": {
        "id": "72b79d1d"
      },
      "outputs": [],
      "source": [
        "\n",
        "text_csv = pd.read_csv(current_dir + '\\\\' + 'output.csv', header=None)\n",
        "data = pd.DataFrame()\n",
        "data['letter'] = text_csv.astype(str).apply(lambda x: ' '.join(x), axis=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "d2ca5774",
      "metadata": {
        "id": "d2ca5774"
      },
      "outputs": [],
      "source": [
        "# Word tokenizer\n",
        "text = data['letter'].tolist()\n",
        "text = ''.join(text)\n",
        "tokens = word_tokenize(text)\n",
        "# Remove punctuation from each token using regex\n",
        "cleaned_tokens = [re.sub(r'[^a-zA-Z0-9]', '', token) for token in tokens]\n",
        "cleaned_tokens = [token for token in cleaned_tokens if token]  # Remove empty tokens\n",
        "cleaned_tokens\n",
        "# Remove stopwords\n",
        "english_stopwords = stopwords.words('english')\n",
        "english_stopwords = set(english_stopwords)\n",
        "\n",
        "tokens_filtered = []\n",
        "for w in cleaned_tokens:\n",
        "  if w not in english_stopwords:\n",
        "    tokens_filtered.append(w)\n",
        "# Lemmatization/Stemming\n",
        "wl = WordNetLemmatizer()\n",
        "ps = PorterStemmer()\n",
        "tokens_lemmatized = [wl.lemmatize(t) for t in tokens_filtered]\n",
        "tokens_stemmed = [ps.stem(t) for t in tokens_lemmatized]\n",
        "tokens = tokens_stemmed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "Zb581iZ-qGtd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "id": "Zb581iZ-qGtd",
        "outputId": "4be353c3-582a-4a0e-ce5c-7882c95917b4"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.microsoft.datawrangler.viewer.v0+json": {
              "columns": [
                {
                  "name": "index",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "0",
                  "rawType": "int64",
                  "type": "integer"
                }
              ],
              "ref": "fc817eab-901d-4075-891b-5e096d9df7d9",
              "rows": [
                [
                  "('we',)",
                  "531"
                ],
                [
                  "('bank',)",
                  "465"
                ],
                [
                  "('custom',)",
                  "394"
                ],
                [
                  "('year',)",
                  "367"
                ],
                [
                  "('busi',)",
                  "323"
                ],
                [
                  "('market',)",
                  "272"
                ],
                [
                  "('compani',)",
                  "249"
                ],
                [
                  "('new',)",
                  "238"
                ],
                [
                  "('the',)",
                  "219"
                ],
                [
                  "('invest',)",
                  "218"
                ],
                [
                  "('continu',)",
                  "212"
                ],
                [
                  "('i',)",
                  "202"
                ],
                [
                  "('client',)",
                  "194"
                ],
                [
                  "('make',)",
                  "188"
                ],
                [
                  "('in',)",
                  "178"
                ],
                [
                  "('capit',)",
                  "172"
                ],
                [
                  "('u',)",
                  "171"
                ],
                [
                  "('1',)",
                  "170"
                ],
                [
                  "('chase',)",
                  "162"
                ],
                [
                  "('growth',)",
                  "160"
                ],
                [
                  "('our',)",
                  "160"
                ],
                [
                  "('need',)",
                  "156"
                ],
                [
                  "('one',)",
                  "155"
                ],
                [
                  "('time',)",
                  "150"
                ],
                [
                  "('mani',)",
                  "149"
                ],
                [
                  "('work',)",
                  "147"
                ],
                [
                  "('peopl',)",
                  "144"
                ],
                [
                  "('manag',)",
                  "135"
                ],
                [
                  "('servic',)",
                  "131"
                ],
                [
                  "('million',)",
                  "129"
                ],
                [
                  "('also',)",
                  "129"
                ],
                [
                  "('thi',)",
                  "125"
                ],
                [
                  "('risk',)",
                  "123"
                ],
                [
                  "('increas',)",
                  "118"
                ],
                [
                  "('jpmorgan',)",
                  "117"
                ],
                [
                  "('store',)",
                  "117"
                ],
                [
                  "('billion',)",
                  "117"
                ],
                [
                  "('global',)",
                  "116"
                ],
                [
                  "('would',)",
                  "115"
                ],
                [
                  "('financi',)",
                  "110"
                ],
                [
                  "('share',)",
                  "109"
                ],
                [
                  "('improv',)",
                  "109"
                ],
                [
                  "('product',)",
                  "108"
                ],
                [
                  "('valu',)",
                  "107"
                ],
                [
                  "('us',)",
                  "107"
                ],
                [
                  "('way',)",
                  "105"
                ],
                [
                  "('larg',)",
                  "105"
                ],
                [
                  "('world',)",
                  "104"
                ],
                [
                  "('oper',)",
                  "104"
                ],
                [
                  "('and',)",
                  "103"
                ]
              ],
              "shape": {
                "columns": 1,
                "rows": 5016
              }
            },
            "text/plain": [
              "we            531\n",
              "bank          465\n",
              "custom        394\n",
              "year          367\n",
              "busi          323\n",
              "             ... \n",
              "caprici         1\n",
              "capital2        1\n",
              "capabiliti      1\n",
              "onethird        1\n",
              "bank23          1\n",
              "Length: 5016, dtype: int64"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pd.DataFrame(tokens).value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bPrwyqyVNK1k",
      "metadata": {
        "id": "bPrwyqyVNK1k"
      },
      "source": [
        "#STEP 2 : Preprocessing and baseline analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d20202c3",
      "metadata": {
        "id": "d20202c3"
      },
      "source": [
        "## Refined Data Extraction and Restructuring\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "134c91eb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "134c91eb",
        "outputId": "1a626850-47d4-4850-e1fa-a6b76a840fe9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DataFrame 'df_yearly_letters' created with yearly segments:\n",
            "  company_name  year_of_report  \\\n",
            "0         CVBF            2015   \n",
            "1         CVBF            2016   \n",
            "2         CVBF            2017   \n",
            "3         HIBB            2015   \n",
            "4         HIBB            2016   \n",
            "\n",
            "                                 full_letter_content  \\\n",
            "0  2015 TO OUR SHAREHOLDERS, CUST OMERS, AND ASSO...   \n",
            "1  2015 TO OUR SHAREHOLDERS, CUST OMERS, AND ASSO...   \n",
            "2  2015 TO OUR SHAREHOLDERS, CUST OMERS, AND ASSO...   \n",
            "3  2015 I am pleased to write you about another s...   \n",
            "4  2015 I am pleased to write you about another s...   \n",
            "\n",
            "                                      yearly_content  \n",
            "0  , CUST OMERS, AND ASSOCIA TES 7 2015 was a sol...  \n",
            "1  Best Banks in America. CVB Financial Corp. ran...  \n",
            "2  . This is our third bank acquired over the pas...  \n",
            "3  about another successful year for Hibbett Spor...  \n",
            "4  as we continue to make progress on major initi...  \n",
            "\n",
            "Total number of yearly segments processed: 24\n",
            "\n",
            "Sample 'yearly_content' for CVBF in 2015 (first 500 characters):\n",
            ", CUST OMERS, AND ASSOCIA TES 7 2015 was a solid year for the bank. CVB Financial Corp. was ranked as the “Best Bank in America” by Forbes. This recognition was particularly rewarding as the rating criteria covered ten different financial metrics and included only the 100 largest banks and thrifts based on asset size in the United States. Citizens Business Bank now has 52 center locations and nearly $8 billion in assets. We certainly have come a long way since 1974, with a single branch location...\n"
          ]
        }
      ],
      "source": [
        "# The read_pdf function is already defined in a previous cell. Assuming it's in scope.\n",
        "# The pdf_list and its content is also assumed to be available from previous cells.\n",
        "\n",
        "def extract_yearly_segment(full_text, year):\n",
        "    \"\"\"\n",
        "    Extracts the text segment relevant to a specific year from the full letter content.\n",
        "    It identifies the start of the target year's section and ends before the next year's section or end of text.\n",
        "    \"\"\"\n",
        "    target_year_str = str(year)\n",
        "    # Consider years up to 2 years beyond the target year as potential delimiters for robustness\n",
        "    all_years_in_scope = sorted([str(y) for y in range(2015, 2020)]) # e.g., 2015, 2016, 2017, 2018, 2019\n",
        "\n",
        "    # Pattern to find the start of the target year's section, potentially followed by common introductory phrases\n",
        "    # The intro phrases are made optional to catch cases where only the year is present.\n",
        "    start_pattern = r\"(?i)\\b\" + re.escape(target_year_str) + r\"(?:\\s*[:,-]?\\s*(?:TO OUR SHAREHOLDERS|Dear Shareholder|DEAR FELLOW SHAREHOLDER|I am pleased to write you|Associates and Customers|Shareholders)?)?\"\n",
        "    start_match = re.search(start_pattern, full_text)\n",
        "\n",
        "    if not start_match:\n",
        "        return \"\"\n",
        "\n",
        "    start_index = start_match.start()\n",
        "    content_start_after_intro = start_index + len(start_match.group(0)) # Start search for next year after this point\n",
        "\n",
        "    # Find the end of the target year's section by looking for the next year in chronological order\n",
        "    end_index = len(full_text)\n",
        "    for y_val in all_years_in_scope:\n",
        "        if int(y_val) > year:\n",
        "            next_year_pattern = r\"\\b\" + re.escape(y_val) + r\"(?:\\s*[:,-]?\\s*(?:TO OUR SHAREHOLDERS|Dear Shareholder|DEAR FELLOW SHAREHOLDER|I am pleased to write you|Associates and Customers|Shareholders)?)?\"\n",
        "            # Search for the next year's pattern *after* the current year's detected introduction\n",
        "            next_year_match = re.search(next_year_pattern, full_text[content_start_after_intro:])\n",
        "            if next_year_match:\n",
        "                end_index = content_start_after_intro + next_year_match.start()\n",
        "                break # Found the nearest next year, so break\n",
        "\n",
        "    # Extract the segment and remove the initial year and introductory phrase from it\n",
        "    segment = full_text[start_index:end_index].strip()\n",
        "    segment = re.sub(start_pattern, '', segment, count=1, flags=re.IGNORECASE).strip()\n",
        "\n",
        "    return segment\n",
        "\n",
        "data_yearly_segments = []\n",
        "years_to_extract = [2015, 2016, 2017]\n",
        "\n",
        "for pdf_path in pdf_list:\n",
        "    # Extract company name (re-using existing logic from previous cells)\n",
        "    filename_with_ext = os.path.basename(pdf_path)\n",
        "    filename_without_ext = os.path.splitext(filename_with_ext)[0]\n",
        "\n",
        "    company_name = filename_without_ext\n",
        "    match_letter = re.search(r'(.*?)(?:\\sLetter[s]? to Shareholders|\\sLetters to shareholders|\\sletter to shareholders)(.*)', filename_without_ext, re.IGNORECASE)\n",
        "    if match_letter:\n",
        "        company_name = match_letter.group(1).strip()\n",
        "    else:\n",
        "        # Fallback for specific cases if no specific pattern is found\n",
        "        if 'Amazone' in company_name:\n",
        "            company_name = 'Amazon'\n",
        "        elif 'Abbott Letters to shareholders Abbott' in company_name:\n",
        "            company_name = 'Abbott'\n",
        "        company_name = company_name.replace('Letters to shareholders', '').strip()\n",
        "\n",
        "    full_letter_content = read_pdf(pdf_path)\n",
        "\n",
        "    for year in years_to_extract:\n",
        "        yearly_content = extract_yearly_segment(full_letter_content, year)\n",
        "        data_yearly_segments.append({\n",
        "            'company_name': company_name,\n",
        "            'year_of_report': year,\n",
        "            'full_letter_content': full_letter_content,\n",
        "            'yearly_content': yearly_content\n",
        "        })\n",
        "\n",
        "df_yearly_letters = pd.DataFrame(data_yearly_segments)\n",
        "\n",
        "print(\"DataFrame 'df_yearly_letters' created with yearly segments:\")\n",
        "print(df_yearly_letters.head())\n",
        "print(f\"\\nTotal number of yearly segments processed: {len(df_yearly_letters)}\")\n",
        "\n",
        "# Verify sample yearly_content for 'CVBF' in '2015'\n",
        "# Ensure to convert 'year_of_report' to numeric for proper filtering if it's not already\n",
        "df_yearly_letters['year_of_report'] = pd.to_numeric(df_yearly_letters['year_of_report'], errors='coerce')\n",
        "cvbf_2015_content = df_yearly_letters[(df_yearly_letters['company_name'] == 'CVBF') & (df_yearly_letters['year_of_report'] == 2015)]['yearly_content'].iloc[0]\n",
        "print(f\"\\nSample 'yearly_content' for CVBF in 2015 (first 500 characters):\\n{cvbf_2015_content[:500]}...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6S-pieM4nhTW",
      "metadata": {
        "id": "6S-pieM4nhTW"
      },
      "source": [
        "##Text Cleaning and Preprocessing to Yearly Segments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "36bc909b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "36bc909b",
        "outputId": "68b10ca7-5552-4a5a-90cf-7a268b9c1219"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'clean_text' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_27196\\1535690310.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf_yearly_letters\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'cleaned_yearly_content'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_yearly_letters\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'yearly_content'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclean_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# Apply preprocess_text and extract the filtered words\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdf_yearly_letters\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'filtered_words_yearly'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_yearly_letters\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'cleaned_yearly_content'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mpreprocess_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mNameError\u001b[0m: name 'clean_text' is not defined"
          ]
        }
      ],
      "source": [
        "df_yearly_letters['cleaned_yearly_content'] = df_yearly_letters['yearly_content'].apply(clean_text)\n",
        "\n",
        "# Apply preprocess_text and extract the filtered words\n",
        "df_yearly_letters['filtered_words_yearly'] = df_yearly_letters['cleaned_yearly_content'].apply(lambda x: preprocess_text(x)[1])\n",
        "\n",
        "print(\"Cleaned and preprocessed yearly content added to 'df_yearly_letters' DataFrame.\")\n",
        "print(df_yearly_letters[['company_name', 'year_of_report', 'yearly_content', 'cleaned_yearly_content', 'filtered_words_yearly']].head())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7746d6f5",
      "metadata": {
        "id": "7746d6f5"
      },
      "source": [
        "## Metrics Calculation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "e9ed013b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9ed013b",
        "outputId": "8dfe12e8-1f1f-4d02-89f9-1b67dd1b3e35"
      },
      "outputs": [
        {
          "ename": "KeyError",
          "evalue": "'cleaned_yearly_content'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\bobch\\anaconda3\\envs\\default\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3801\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3802\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3803\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\bobch\\anaconda3\\envs\\default\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\bobch\\anaconda3\\envs\\default\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
            "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
            "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
            "\u001b[1;31mKeyError\u001b[0m: 'cleaned_yearly_content'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_27196\\4236121704.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msimple_yearly_stats\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_yearly_letters\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'cleaned_yearly_content'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcalculate_simple_stats\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mstats_df_yearly\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjson_normalize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msimple_yearly_stats\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdf_yearly_letters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf_yearly_letters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstats_df_yearly\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\bobch\\anaconda3\\envs\\default\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3805\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3806\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3807\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3808\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3809\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\bobch\\anaconda3\\envs\\default\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3802\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3803\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3804\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3805\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3806\u001b[0m                 \u001b[1;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mKeyError\u001b[0m: 'cleaned_yearly_content'"
          ]
        }
      ],
      "source": [
        "simple_yearly_stats = df_yearly_letters['cleaned_yearly_content'].apply(calculate_simple_stats)\n",
        "\n",
        "stats_df_yearly = pd.json_normalize(simple_yearly_stats)\n",
        "df_yearly_letters = pd.concat([df_yearly_letters, stats_df_yearly], axis=1)\n",
        "\n",
        "# Calculate top bigrams for yearly segments\n",
        "df_yearly_letters['top_bigrams_yearly'] = df_yearly_letters['filtered_words_yearly'].apply(lambda x: get_top_ngrams(x))\n",
        "\n",
        "print(\"Simple baseline statistics and top bigrams calculated for yearly segments.\")\n",
        "print(df_yearly_letters[['company_name', 'year_of_report', 'word_count_simple', 'sentence_count_simple', 'avg_sentence_length_simple', 'unique_word_ratio_simple', 'top_bigrams_yearly']].head())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d84cf0ae",
      "metadata": {
        "id": "d84cf0ae"
      },
      "source": [
        "## Visualization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "59cb1059",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "59cb1059",
        "outputId": "97060124-84a5-4197-eb74-232941df87e7"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "Could not interpret value `word_count_simple` for parameter `y`",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_27196\\3163562476.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# 1. Yearly Evolution of Simple Word Count per Company\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m7\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0msns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlineplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf_yearly_letters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'year_of_report'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'word_count_simple'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'company_name'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmarker\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'o'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Yearly Evolution of Simple Word Count per Company (Yearly Segments)'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Year of Report'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\bobch\\anaconda3\\envs\\default\\lib\\site-packages\\seaborn\\relational.py\u001b[0m in \u001b[0;36mlineplot\u001b[1;34m(data, x, y, hue, size, style, units, palette, hue_order, hue_norm, sizes, size_order, size_norm, dashes, markers, style_order, estimator, errorbar, n_boot, seed, orient, sort, err_style, err_kws, legend, ci, ax, **kwargs)\u001b[0m\n\u001b[0;32m    610\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    611\u001b[0m     \u001b[0mvariables\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_LinePlotter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_semantics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlocals\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 612\u001b[1;33m     p = _LinePlotter(\n\u001b[0m\u001b[0;32m    613\u001b[0m         \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvariables\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvariables\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    614\u001b[0m         \u001b[0mestimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_boot\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_boot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrorbar\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrorbar\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\bobch\\anaconda3\\envs\\default\\lib\\site-packages\\seaborn\\relational.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, variables, estimator, n_boot, seed, errorbar, sort, orient, err_style, err_kws, legend)\u001b[0m\n\u001b[0;32m    363\u001b[0m         )\n\u001b[0;32m    364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 365\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvariables\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvariables\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    366\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    367\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\bobch\\anaconda3\\envs\\default\\lib\\site-packages\\seaborn\\_oldcore.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, variables)\u001b[0m\n\u001b[0;32m    638\u001b[0m         \u001b[1;31m# information for numeric axes would be information about log scales.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    639\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_var_ordered\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"x\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"y\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m}\u001b[0m  \u001b[1;31m# alt., used DefaultDict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 640\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massign_variables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvariables\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    641\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    642\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mvar\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcls\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_semantic_mappings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\bobch\\anaconda3\\envs\\default\\lib\\site-packages\\seaborn\\_oldcore.py\u001b[0m in \u001b[0;36massign_variables\u001b[1;34m(self, data, variables)\u001b[0m\n\u001b[0;32m    699\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    700\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_format\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"long\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 701\u001b[1;33m             plot_data, variables = self._assign_variables_longform(\n\u001b[0m\u001b[0;32m    702\u001b[0m                 \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mvariables\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    703\u001b[0m             )\n",
            "\u001b[1;32mc:\\Users\\bobch\\anaconda3\\envs\\default\\lib\\site-packages\\seaborn\\_oldcore.py\u001b[0m in \u001b[0;36m_assign_variables_longform\u001b[1;34m(self, data, **kwargs)\u001b[0m\n\u001b[0;32m    936\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    937\u001b[0m                 \u001b[0merr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mf\"Could not interpret value `{val}` for parameter `{key}`\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 938\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    939\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    940\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mValueError\u001b[0m: Could not interpret value `word_count_simple` for parameter `y`"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 1080x504 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# 1. Yearly Evolution of Simple Word Count per Company\n",
        "plt.figure(figsize=(15, 7))\n",
        "sns.lineplot(data=df_yearly_letters, x='year_of_report', y='word_count_simple', hue='company_name', marker='o')\n",
        "plt.title('Yearly Evolution of Simple Word Count per Company (Yearly Segments)')\n",
        "plt.xlabel('Year of Report')\n",
        "plt.ylabel('Simple Word Count')\n",
        "plt.xticks(df_yearly_letters['year_of_report'].unique().astype(int)) # Ensure integer years on x-axis\n",
        "plt.legend(title='Company Name')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# 2. Yearly Evolution of Simple Average Sentence Length per Company\n",
        "plt.figure(figsize=(15, 7))\n",
        "sns.lineplot(data=df_yearly_letters, x='year_of_report', y='avg_sentence_length_simple', hue='company_name', marker='o')\n",
        "plt.title('Yearly Evolution of Simple Average Sentence Length per Company (Yearly Segments)')\n",
        "plt.xlabel('Year of Report')\n",
        "plt.ylabel('Simple Average Sentence Length')\n",
        "plt.xticks(df_yearly_letters['year_of_report'].unique().astype(int)) # Ensure integer years on x-axis\n",
        "plt.legend(title='Company Name')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# 3. Aggregate data for cross-company comparison (using mean)\n",
        "company_avg_yearly_stats = df_yearly_letters.groupby('company_name').agg({\n",
        "    'word_count_simple': 'mean',\n",
        "    'avg_sentence_length_simple': 'mean'\n",
        "}).reset_index()\n",
        "\n",
        "# 4. Comparison of Average Simple Word Count Across Companies (Yearly Segments)\n",
        "plt.figure(figsize=(15, 7))\n",
        "sns.barplot(data=company_avg_yearly_stats, x='company_name', y='word_count_simple', hue='company_name', palette='viridis', legend=False)\n",
        "plt.title('Comparison of Average Simple Word Count Across Companies (Yearly Segments)')\n",
        "plt.xlabel('Company Name')\n",
        "plt.ylabel('Average Simple Word Count')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 5. Comparison of Average Simple Sentence Length Across Companies (Yearly Segments)\n",
        "plt.figure(figsize=(15, 7))\n",
        "sns.barplot(data=company_avg_yearly_stats, x='company_name', y='avg_sentence_length_simple', hue='company_name', palette='magma', legend=False)\n",
        "plt.title('Comparison of Average Simple Sentence Length Across Companies (Yearly Segments)')\n",
        "plt.xlabel('Company Name')\n",
        "plt.ylabel('Average Simple Sentence Length')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"Visualizations for yearly trends and cross-company comparisons generated for yearly segments.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bdd893e3",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "default",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
